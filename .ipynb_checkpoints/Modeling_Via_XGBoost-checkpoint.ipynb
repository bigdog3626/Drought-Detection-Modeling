{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Mismatched version between the Python package and the native shared object.  Python package version: 1.7.2. Shared object version: 1.5.0. Shared object is loaded from: /Users/charlesmeyer/opt/anaconda3/envs/Drought-Detection-Modeling/lib/libxgboost.dylib.\nLikely cause:\n  * XGBoost is first installed with anaconda then upgraded with pip. To fix it please remove one of the installations.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [1], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimpute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SimpleImputer\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StandardScaler\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mxgboost\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mxgb\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompose\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ColumnTransformer\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdecomposition\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PCA\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/Drought-Detection-Modeling/lib/python3.10/site-packages/xgboost/__init__.py:7\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"XGBoost: eXtreme Gradient Boosting library.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03mContributors: https://github.com/dmlc/xgboost/blob/master/CONTRIBUTORS.md\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tracker  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m collective, dask, rabit\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      9\u001b[0m     Booster,\n\u001b[1;32m     10\u001b[0m     DataIter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     15\u001b[0m     build_info,\n\u001b[1;32m     16\u001b[0m )\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtracker\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RabitTracker  \u001b[38;5;66;03m# noqa\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/Drought-Detection-Modeling/lib/python3.10/site-packages/xgboost/collective.py:12\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_typing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _T\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _LIB, _check_call, c_str, py_str, from_pystr_to_cstr\n\u001b[1;32m     14\u001b[0m LOGGER \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mgetLogger(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[xgboost.collective]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minit\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39margs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/Drought-Detection-Modeling/lib/python3.10/site-packages/xgboost/core.py:264\u001b[0m\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# load the XGBoost library globally\u001b[39;00m\n\u001b[0;32m--> 264\u001b[0m _LIB \u001b[38;5;241m=\u001b[39m \u001b[43m_load_lib\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    267\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_call\u001b[39m(ret: \u001b[38;5;28mint\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    268\u001b[0m     \u001b[38;5;124;03m\"\"\"Check the return value of C API call\u001b[39;00m\n\u001b[1;32m    269\u001b[0m \n\u001b[1;32m    270\u001b[0m \u001b[38;5;124;03m    This function will raise exception when error occurs.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    276\u001b[0m \u001b[38;5;124;03m        return value from API calls\u001b[39;00m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/Drought-Detection-Modeling/lib/python3.10/site-packages/xgboost/core.py:258\u001b[0m, in \u001b[0;36m_load_lib\u001b[0;34m()\u001b[0m\n\u001b[1;32m    249\u001b[0m     libver_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin((\u001b[38;5;28mstr\u001b[39m(v) \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m libver))\n\u001b[1;32m    250\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    251\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMismatched version between the Python package and the native shared \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    252\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124mobject.  Python package version: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpyver_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Shared object \u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplease remove one of the installations.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    257\u001b[0m     )\n\u001b[0;32m--> 258\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m lib\n",
      "\u001b[0;31mValueError\u001b[0m: Mismatched version between the Python package and the native shared object.  Python package version: 1.7.2. Shared object version: 1.5.0. Shared object is loaded from: /Users/charlesmeyer/opt/anaconda3/envs/Drought-Detection-Modeling/lib/libxgboost.dylib.\nLikely cause:\n  * XGBoost is first installed with anaconda then upgraded with pip. To fix it please remove one of the installations."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import xgboost as xgb\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_parquet('./Data/Tifton_SPI_FE.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "color_pal = sns.color_palette()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15, 10))\n",
    "sns.boxplot(data=df, x='year', y='SPI')\n",
    "ax.set_title('SPI by year')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df.SPI.plot(style='.',\n",
    "            figsize=(15, 5),\n",
    "            color=color_pal[0],\n",
    "            title=\"SPI\"\n",
    "            )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train = df.loc[df.index < '01-01-2015']\n",
    "test = df.loc[df.index >= '01-01-2015']\n",
    "fig, ax = plt.subplots(figsize=(15, 5))\n",
    "train.SPI.plot(ax=ax, label='Training Set', title='Data Train/Test Split')\n",
    "test.SPI.plot(ax=ax, label='Test Set')\n",
    "ax.axvline('01-01-2015', color='black', ls='--')\n",
    "ax.legend(['Training Set', 'Test Set'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df[['SPI']].loc[(df.index > '01-01-2012') & (df.index < '01-31-2012')].plot(figsize=(15, 5), title='Month Of Data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df = df.drop(['hour'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outlier Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df['SPI'].plot(kind='hist',bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df.query('SPI > 1')['SPI'] \\\n",
    "    .plot(style='.',\n",
    "          figsize=(15, 5),\n",
    "          color=color_pal[5],\n",
    "          title='Outliers')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time series cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "tss = TimeSeriesSplit(n_splits=5,gap=24)\n",
    "df = df.sort_index()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(5, 1, figsize=(15, 15), sharex=True)\n",
    "\n",
    "fold = 0\n",
    "for train_idx, val_idx in tss.split(df):\n",
    "    train = df.iloc[train_idx]\n",
    "    test = df.iloc[val_idx]\n",
    "    train['SPI'].plot(ax=axs[fold],\n",
    "                          label='Training Set',\n",
    "                          title=f'Data Train/Test Split Fold {fold}')\n",
    "    test['SPI'].plot(ax=axs[fold],\n",
    "                         label='Test Set')\n",
    "    axs[fold].axvline(test.index.min(), color='black', ls='--')\n",
    "    fold += 1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def add_lags(df):\n",
    "    target_map = df['SPI'].to_dict()\n",
    "    df['lag1'] = (df.index - pd.Timedelta('364 days')).map(target_map)\n",
    "    df['lag2'] = (df.index - pd.Timedelta('728 days')).map(target_map)\n",
    "    df['lag3'] = (df.index - pd.Timedelta('1092 days')).map(target_map)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df = add_lags(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df.head(1).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "FEATURES = ['Precipitation Accumulation  (In)',\n",
    "            'Air Temperature Observed  (Degc)',\n",
    "            'Air Temperature Maximum  (Degc)',\n",
    "            'Air Temperature Minimum  (Degc)',\n",
    "            'Air Temperature Average  (Degc)',\n",
    "            'Soil Moisture Percent -2\" (Pct)',\n",
    "            'Soil Moisture Percent -4\" (Pct)',\n",
    "            'Soil Moisture Percent -8\" (Pct)',\n",
    "            'Soil Moisture Percent -20\" (Pct)',\n",
    "            'Soil Moisture Percent -40\" (Pct)',\n",
    "            'Soil Temperature Observed -2\" (Degc)',\n",
    "            'Soil Temperature Observed -4\" (Degc)',\n",
    "            'Soil Temperature Observed -8\" (Degc)',\n",
    "            'Soil Temperature Observed -20\" (Degc)',\n",
    "            'Soil Temperature Observed -40\" (Degc)',\n",
    "            'Salinity -2\" (Gram)',\n",
    "            'Salinity -4\" (Gram)',\n",
    "            'Salinity -8\" (Gram)',\n",
    "            'Salinity -20\" (Gram)',\n",
    "            'Salinity -40\" (Gram)',\n",
    "            'Wind Direction Average  (Degr)',\n",
    "            'Wind Speed Average  (Mph)',\n",
    "            'PRCP',\n",
    "            'year',\n",
    "            'month',\n",
    "            'day',\n",
    "            'dayofweek',\n",
    "            'weekday',\n",
    "            'quarter',\n",
    "            'dayofyear',\n",
    "            'dayofmonth',\n",
    "            'weekofyear',\n",
    "            'date_offset',\n",
    "            'season','lag1','lag2','lag3']\n",
    "TARGET = 'SPI'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tss = TimeSeriesSplit(n_splits=5, gap=24)\n",
    "df = df.sort_index()\n",
    "fold = 0\n",
    "preds = []\n",
    "scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "df['season'] = le.fit_transform(df['season'])\n",
    "df['weekday'] = le.fit_transform(df['weekday'])\n",
    "df['day'] = le.fit_transform(df['day'])\n",
    "df = df.drop(['date', 'PRCP_ECDF'], axis=1)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train = df.loc[df.index < '01-01-2015']\n",
    "test = df.loc[df.index >= '01-01-2015']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_train = train[FEATURES]\n",
    "y_train = train[TARGET]\n",
    "\n",
    "X_test = test[FEATURES]\n",
    "y_test = test[TARGET]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up pipeline\n",
    "numeric_features = FEATURES[:-15]\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"mean\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    (\"num_transform\", numeric_transformer, numeric_features),\n",
    "\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pca = PCA(svd_solver='full', n_components=10,random_state=42)\n",
    "xgb_reg = xgb.XGBRegressor()\n",
    "xgb_pipeline = Pipeline(steps=[(\"preprocesser\", preprocessor), ('pca', pca), (\"clf\", xgb_reg)])\n",
    "xgb_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fi = pd.DataFrame(data=reg.feature_importances_,\n",
    "             index=reg.feature_names_in_,\n",
    "             columns=['importance'])\n",
    "fi.sort_values('importance').plot(kind='barh', title='Feature Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
