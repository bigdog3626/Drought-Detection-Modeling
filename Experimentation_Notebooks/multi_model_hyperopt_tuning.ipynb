{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import warnings\n",
    "from utils import collect_error_metrics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost\n",
    "from hyperopt import fmin, hp, space_eval, tpe, STATUS_OK, Trials, partial\n",
    "from hyperopt.pyll import scope\n",
    "from sklearn import set_config\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import make_scorer, mean_squared_error\n",
    "from sklearn.svm import SVR\n",
    "from plotly import express as px\n",
    "from plotly import graph_objects as go\n",
    "from plotly import offline as pyo\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.metrics import make_scorer, mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.utils import check_random_state\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "set_config(display='diagram')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "df = pd.read_parquet('./Data/Tifton_SPI_FE.parquet')\n",
    "df = df.drop(['date', 'hour'], axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "# def add_lags(df):\n",
    "#     target_map = df['SPI'].to_dict()\n",
    "#     df['lag1'] = (df.index - pd.Timedelta('364 days')).map(target_map)\n",
    "#     df['lag2'] = (df.index - pd.Timedelta('728 days')).map(target_map)\n",
    "#     df['lag3'] = (df.index - pd.Timedelta('1092 days')).map(target_map)\n",
    "#     return df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "# df = add_lags(df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "df['season'] = le.fit_transform(df['season'])\n",
    "df['weekday'] = le.fit_transform(df['weekday'])\n",
    "df['day'] = le.fit_transform(df['day'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "train = df.loc[df.index < '01-01-2015']\n",
    "test = df.loc[df.index >= '01-01-2015']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "FEATURES = ['prcp_accum', 'air_temp_avg', 'smp_2', 'smp_4', 'smp_8', 'smp_20',\n",
    "            'smp_40', 'soil_temp_2', 'soil_temp_4', 'soil_temp_8', 'soil_temp_20',\n",
    "            'soil_temp_40', 'wind_dir_avg', 'wind_speed_avg', 'PRCP', 'year',\n",
    "            'month', 'day', 'dayofweek', 'weekday', 'quarter', 'dayofyear',\n",
    "            'dayofmonth', 'weekofyear', 'date_offset', 'season', 'soil_temp_avg',\n",
    "            'smp_avg']\n",
    "TARGET = 'SPI'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "X_train = train[FEATURES]\n",
    "y_train = train[TARGET]\n",
    "X_test = test[FEATURES]\n",
    "y_test = test[TARGET]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "data": {
      "text/plain": "ColumnTransformer(remainder='passthrough',\n                  transformers=[('num',\n                                 Pipeline(steps=[('imputer',\n                                                  SimpleImputer(strategy='median')),\n                                                 ('scaler', StandardScaler())]),\n                                 ['prcp_accum', 'air_temp_avg', 'smp_2',\n                                  'smp_4', 'smp_8', 'smp_20', 'smp_40',\n                                  'soil_temp_2', 'soil_temp_4', 'soil_temp_8',\n                                  'soil_temp_20', 'soil_temp_40',\n                                  'wind_dir_avg', 'wind_speed_avg', 'PRCP'])])",
      "text/html": "<style>#sk-b5014e4c-0b77-4113-89b5-d3677d61cd81 {color: black;background-color: white;}#sk-b5014e4c-0b77-4113-89b5-d3677d61cd81 pre{padding: 0;}#sk-b5014e4c-0b77-4113-89b5-d3677d61cd81 div.sk-toggleable {background-color: white;}#sk-b5014e4c-0b77-4113-89b5-d3677d61cd81 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-b5014e4c-0b77-4113-89b5-d3677d61cd81 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-b5014e4c-0b77-4113-89b5-d3677d61cd81 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-b5014e4c-0b77-4113-89b5-d3677d61cd81 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-b5014e4c-0b77-4113-89b5-d3677d61cd81 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-b5014e4c-0b77-4113-89b5-d3677d61cd81 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-b5014e4c-0b77-4113-89b5-d3677d61cd81 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-b5014e4c-0b77-4113-89b5-d3677d61cd81 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-b5014e4c-0b77-4113-89b5-d3677d61cd81 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-b5014e4c-0b77-4113-89b5-d3677d61cd81 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-b5014e4c-0b77-4113-89b5-d3677d61cd81 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-b5014e4c-0b77-4113-89b5-d3677d61cd81 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-b5014e4c-0b77-4113-89b5-d3677d61cd81 div.sk-estimator:hover {background-color: #d4ebff;}#sk-b5014e4c-0b77-4113-89b5-d3677d61cd81 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-b5014e4c-0b77-4113-89b5-d3677d61cd81 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-b5014e4c-0b77-4113-89b5-d3677d61cd81 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}#sk-b5014e4c-0b77-4113-89b5-d3677d61cd81 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;}#sk-b5014e4c-0b77-4113-89b5-d3677d61cd81 div.sk-item {z-index: 1;}#sk-b5014e4c-0b77-4113-89b5-d3677d61cd81 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;}#sk-b5014e4c-0b77-4113-89b5-d3677d61cd81 div.sk-parallel::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}#sk-b5014e4c-0b77-4113-89b5-d3677d61cd81 div.sk-parallel-item {display: flex;flex-direction: column;position: relative;background-color: white;}#sk-b5014e4c-0b77-4113-89b5-d3677d61cd81 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-b5014e4c-0b77-4113-89b5-d3677d61cd81 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-b5014e4c-0b77-4113-89b5-d3677d61cd81 div.sk-parallel-item:only-child::after {width: 0;}#sk-b5014e4c-0b77-4113-89b5-d3677d61cd81 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;position: relative;}#sk-b5014e4c-0b77-4113-89b5-d3677d61cd81 div.sk-label label {font-family: monospace;font-weight: bold;background-color: white;display: inline-block;line-height: 1.2em;}#sk-b5014e4c-0b77-4113-89b5-d3677d61cd81 div.sk-label-container {position: relative;z-index: 2;text-align: center;}#sk-b5014e4c-0b77-4113-89b5-d3677d61cd81 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-b5014e4c-0b77-4113-89b5-d3677d61cd81 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-b5014e4c-0b77-4113-89b5-d3677d61cd81\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n                  transformers=[(&#x27;num&#x27;,\n                                 Pipeline(steps=[(&#x27;imputer&#x27;,\n                                                  SimpleImputer(strategy=&#x27;median&#x27;)),\n                                                 (&#x27;scaler&#x27;, StandardScaler())]),\n                                 [&#x27;prcp_accum&#x27;, &#x27;air_temp_avg&#x27;, &#x27;smp_2&#x27;,\n                                  &#x27;smp_4&#x27;, &#x27;smp_8&#x27;, &#x27;smp_20&#x27;, &#x27;smp_40&#x27;,\n                                  &#x27;soil_temp_2&#x27;, &#x27;soil_temp_4&#x27;, &#x27;soil_temp_8&#x27;,\n                                  &#x27;soil_temp_20&#x27;, &#x27;soil_temp_40&#x27;,\n                                  &#x27;wind_dir_avg&#x27;, &#x27;wind_speed_avg&#x27;, &#x27;PRCP&#x27;])])</pre><b>Please rerun this cell to show the HTML repr or trust the notebook.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"eb9af5c4-eed1-49d8-99b2-de3e1bdb3fd6\" type=\"checkbox\" ><label for=\"eb9af5c4-eed1-49d8-99b2-de3e1bdb3fd6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n                  transformers=[(&#x27;num&#x27;,\n                                 Pipeline(steps=[(&#x27;imputer&#x27;,\n                                                  SimpleImputer(strategy=&#x27;median&#x27;)),\n                                                 (&#x27;scaler&#x27;, StandardScaler())]),\n                                 [&#x27;prcp_accum&#x27;, &#x27;air_temp_avg&#x27;, &#x27;smp_2&#x27;,\n                                  &#x27;smp_4&#x27;, &#x27;smp_8&#x27;, &#x27;smp_20&#x27;, &#x27;smp_40&#x27;,\n                                  &#x27;soil_temp_2&#x27;, &#x27;soil_temp_4&#x27;, &#x27;soil_temp_8&#x27;,\n                                  &#x27;soil_temp_20&#x27;, &#x27;soil_temp_40&#x27;,\n                                  &#x27;wind_dir_avg&#x27;, &#x27;wind_speed_avg&#x27;, &#x27;PRCP&#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"f2b4007a-0c9c-4592-9e56-10c907dc94ac\" type=\"checkbox\" ><label for=\"f2b4007a-0c9c-4592-9e56-10c907dc94ac\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">num</label><div class=\"sk-toggleable__content\"><pre>[&#x27;prcp_accum&#x27;, &#x27;air_temp_avg&#x27;, &#x27;smp_2&#x27;, &#x27;smp_4&#x27;, &#x27;smp_8&#x27;, &#x27;smp_20&#x27;, &#x27;smp_40&#x27;, &#x27;soil_temp_2&#x27;, &#x27;soil_temp_4&#x27;, &#x27;soil_temp_8&#x27;, &#x27;soil_temp_20&#x27;, &#x27;soil_temp_40&#x27;, &#x27;wind_dir_avg&#x27;, &#x27;wind_speed_avg&#x27;, &#x27;PRCP&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"9983ad76-ebad-4241-a271-7f28189423c8\" type=\"checkbox\" ><label for=\"9983ad76-ebad-4241-a271-7f28189423c8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(strategy=&#x27;median&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"1a9bbc11-2958-4926-acc0-365c2e5d67a0\" type=\"checkbox\" ><label for=\"1a9bbc11-2958-4926-acc0-365c2e5d67a0\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"64388e28-acd7-49b5-a5bc-f48c6e9ca58b\" type=\"checkbox\" ><label for=\"64388e28-acd7-49b5-a5bc-f48c6e9ca58b\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">remainder</label><div class=\"sk-toggleable__content\"><pre></pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"db06b9df-e3fb-4a8f-80d7-0220b424bc7f\" type=\"checkbox\" ><label for=\"db06b9df-e3fb-4a8f-80d7-0220b424bc7f\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">passthrough</label><div class=\"sk-toggleable__content\"><pre>passthrough</pre></div></div></div></div></div></div></div></div></div></div>"
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "numeric_features = FEATURES[0:15] + FEATURES[26:28]\n",
    "numeric_transformer = Pipeline(\n",
    "    steps=[('imputer', SimpleImputer(strategy='median')), ('scaler', StandardScaler())])\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_features)\n",
    "    ],\n",
    "    remainder='passthrough',\n",
    ")\n",
    "preprocessor"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "data": {
      "text/plain": "['preprocessor.pkl']"
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(preprocessor, 'preprocessor.pkl')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "GRADIENT_BOOSTING_REGRESSOR = \"gradient_boosting_regressor\"\n",
    "KWARGS = \"kwargs\"\n",
    "LEARNING_RATE = \"learning_rate\"\n",
    "LINEAR_REGRESSION = \"linear_regression\"\n",
    "MAX_DEPTH = \"max_depth\"\n",
    "MODEL = \"model\"\n",
    "MODEL_CHOICE = \"model_choice\"\n",
    "NORMALIZE = \"normalize\"\n",
    "N_ESTIMATORS = \"n_estimators\"\n",
    "RANDOM_FOREST_REGRESSOR = \"random_forest_regressor\"\n",
    "RANDOM_STATE = \"random_state\"\n",
    "SGD_REGRESSOR = \"stochastic_gradient_descent_regressor\"\n",
    "XGB_REGRESSOR = \"xgboost_regressor\"\n",
    "SEED = 0\n",
    "\n",
    "stochastic_gradient_descent_regressor = {\n",
    "    MODEL: SGD_REGRESSOR,\n",
    "    KWARGS: {\n",
    "        'loss': hp.choice(f'{SGD_REGRESSOR}__loss',\n",
    "                          ['squared_loss', 'huber', 'epsilon_insensitive', 'squared_epsilon_insensitive']),\n",
    "        'penalty': hp.choice(f'{SGD_REGRESSOR}__penalty', ['none', 'l2', 'l1', 'elasticnet']),\n",
    "        'alpha': hp.uniform(f'{SGD_REGRESSOR}__alpha', 0.0001, 0.1),\n",
    "        'l1_ratio': hp.uniform(f'{SGD_REGRESSOR}__l1_ratio', 0, 1),\n",
    "        'max_iter': hp.choice(f'{SGD_REGRESSOR}__max_iter', [100, 200, 300, 400, 500]),\n",
    "        'epsilon': hp.uniform(f'{SGD_REGRESSOR}__epsilon', 0.001, 0.1),\n",
    "        'learning_rate': hp.choice(f'{SGD_REGRESSOR}__learning_rate',\n",
    "                                   ['constant', 'optimal', 'invscaling', 'adaptive']),\n",
    "        'eta0': hp.uniform(f'{SGD_REGRESSOR}__eta0', 0.0001, 1),\n",
    "        'power_t': hp.uniform(f'{SGD_REGRESSOR}__power_t', 0.5, 1.5),\n",
    "        'validation_fraction': hp.uniform(f'{SGD_REGRESSOR}__validation_fraction', 0.1, 0.5),\n",
    "        'n_iter_no_change': hp.choice(f'{SGD_REGRESSOR}__n_iter_no_change', [5, 10, 15, 20, 25, 30, 35, 40, 45, 50]),\n",
    "        RANDOM_STATE: 0,\n",
    "        'early_stopping': True,\n",
    "        'verbose': 3,\n",
    "        'tol': 0.1\n",
    "    },\n",
    "}\n",
    "\n",
    "xtreme_gradient_boost_regressor = {\n",
    "    MODEL: XGB_REGRESSOR,\n",
    "    KWARGS: {\n",
    "\n",
    "        'max_depth': hp.choice(f'{XGB_REGRESSOR}__max_depth', [6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18]),\n",
    "        'gamma': hp.uniform(f'{XGB_REGRESSOR}__gamma', 1, 9),\n",
    "        'reg_alpha': hp.quniform(f'{XGB_REGRESSOR}__reg_alpha', 40, 180, 1),\n",
    "        'reg_lambda': hp.uniform(f'{XGB_REGRESSOR}__reg_lambda', 0, 1),\n",
    "        'colsample_bytree': hp.uniform(f'{XGB_REGRESSOR}__colsample_bytree', 0.5, 1),\n",
    "        'min_child_weight': hp.quniform(f'{XGB_REGRESSOR}__min_child_weight', 0, 10, 1),\n",
    "        'n_estimators': hp.choice(f'{XGB_REGRESSOR}__n_estimators', [80, 100, 200, 300, 400, 500]),\n",
    "        'learning_rate': hp.choice(f'{XGB_REGRESSOR}__learning_rate', [0.0001, 0.001, 0.01, 0.1, 0.2, 0.3]),\n",
    "        'seed': 0,\n",
    "\n",
    "    }\n",
    "}\n",
    "\n",
    "random_forest_regressor = {\n",
    "    MODEL: RANDOM_FOREST_REGRESSOR,\n",
    "    KWARGS: {\n",
    "        N_ESTIMATORS: scope.int(\n",
    "            hp.quniform(f\"{RANDOM_FOREST_REGRESSOR}__{N_ESTIMATORS}\", 50, 150, 1)\n",
    "        ),\n",
    "        MAX_DEPTH: scope.int(\n",
    "            hp.quniform(f\"{RANDOM_FOREST_REGRESSOR}__{MAX_DEPTH}\", 2, 12, 1)\n",
    "        ),\n",
    "        RANDOM_STATE: 0,\n",
    "    },\n",
    "}\n",
    "\n",
    "gradient_boosting_regressor = {\n",
    "    MODEL: GRADIENT_BOOSTING_REGRESSOR,\n",
    "    KWARGS: {\n",
    "        LEARNING_RATE: scope.float(\n",
    "            hp.uniform(f\"{GRADIENT_BOOSTING_REGRESSOR}__{LEARNING_RATE}\", 0.01, 0.15, )\n",
    "        ),\n",
    "        N_ESTIMATORS: scope.int(\n",
    "            hp.quniform(f\"{GRADIENT_BOOSTING_REGRESSOR}__{N_ESTIMATORS}\", 50, 150, 1)\n",
    "        ),\n",
    "        MAX_DEPTH: scope.int(\n",
    "            hp.quniform(f\"{GRADIENT_BOOSTING_REGRESSOR}__{MAX_DEPTH}\", 2, 12, 1)\n",
    "        ),\n",
    "        RANDOM_STATE: 0,\n",
    "    },\n",
    "}\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [
    "space = {\n",
    "    MODEL_CHOICE: hp.choice(\n",
    "        MODEL_CHOICE, [random_forest_regressor, gradient_boosting_regressor, stochastic_gradient_descent_regressor,\n",
    "                       xtreme_gradient_boost_regressor],\n",
    "    )\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "LOSS = 'loss'\n",
    "STATUS = 'status'\n",
    "\n",
    "MODELS = {\n",
    "    GRADIENT_BOOSTING_REGRESSOR: GradientBoostingRegressor,\n",
    "    RANDOM_FOREST_REGRESSOR: RandomForestRegressor,\n",
    "    SGD_REGRESSOR: SGDRegressor,\n",
    "    XGB_REGRESSOR: xgboost.XGBRegressor\n",
    "}\n",
    "\n",
    "mse_scorer = make_scorer(mean_squared_error)\n",
    "\n",
    "\n",
    "def sample_to_model(sample):\n",
    "    kwargs = sample[MODEL_CHOICE][KWARGS]\n",
    "    return MODELS[sample[MODEL_CHOICE][MODEL]](**kwargs)\n",
    "\n",
    "\n",
    "def objective(sample, dataset_df, features, target):\n",
    "    model = sample_to_model(sample)\n",
    "    rng = check_random_state(0)\n",
    "    cv = KFold(n_splits=10, random_state=rng, shuffle=True)\n",
    "    mse = cross_val_score(\n",
    "        model,\n",
    "        preprocessor.fit_transform(dataset_df.loc[:, features]),\n",
    "        dataset_df.loc[:, target],\n",
    "        scoring=mse_scorer,\n",
    "        cv=cv,\n",
    "        n_jobs=-1, error_score=0.99\n",
    "    )\n",
    "    return {LOSS: np.mean(mse), STATUS: STATUS_OK}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [
    "SPI_objective = partial(\n",
    "    objective, dataset_df=df, features=FEATURES, target=TARGET\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 358/1000 [04:07<07:24,  1.44trial/s, best loss: 3656.1965566377417]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_22720\\2905741378.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[0mtrials\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mTrials\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 3\u001B[1;33m \u001B[0mbest\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mfmin\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mSPI_objective\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mspace\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtpe\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msuggest\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m1000\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtrials\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mtrials\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mrstate\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrandom\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdefault_rng\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mSEED\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\hyperopt\\fmin.py\u001B[0m in \u001B[0;36mfmin\u001B[1;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001B[0m\n\u001B[0;32m    538\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    539\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mallow_trials_fmin\u001B[0m \u001B[1;32mand\u001B[0m \u001B[0mhasattr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtrials\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\"fmin\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 540\u001B[1;33m         return trials.fmin(\n\u001B[0m\u001B[0;32m    541\u001B[0m             \u001B[0mfn\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    542\u001B[0m             \u001B[0mspace\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\hyperopt\\base.py\u001B[0m in \u001B[0;36mfmin\u001B[1;34m(self, fn, space, algo, max_evals, timeout, loss_threshold, max_queue_len, rstate, verbose, pass_expr_memo_ctrl, catch_eval_exceptions, return_argmin, show_progressbar, early_stop_fn, trials_save_file)\u001B[0m\n\u001B[0;32m    669\u001B[0m         \u001B[1;32mfrom\u001B[0m \u001B[1;33m.\u001B[0m\u001B[0mfmin\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mfmin\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    670\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 671\u001B[1;33m         return fmin(\n\u001B[0m\u001B[0;32m    672\u001B[0m             \u001B[0mfn\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    673\u001B[0m             \u001B[0mspace\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\hyperopt\\fmin.py\u001B[0m in \u001B[0;36mfmin\u001B[1;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001B[0m\n\u001B[0;32m    584\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    585\u001B[0m     \u001B[1;31m# next line is where the fmin is actually executed\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 586\u001B[1;33m     \u001B[0mrval\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mexhaust\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    587\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    588\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mreturn_argmin\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\hyperopt\\fmin.py\u001B[0m in \u001B[0;36mexhaust\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    362\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mexhaust\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    363\u001B[0m         \u001B[0mn_done\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtrials\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 364\u001B[1;33m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrun\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmax_evals\u001B[0m \u001B[1;33m-\u001B[0m \u001B[0mn_done\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mblock_until_done\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0masynchronous\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    365\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtrials\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrefresh\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    366\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\hyperopt\\fmin.py\u001B[0m in \u001B[0;36mrun\u001B[1;34m(self, N, block_until_done)\u001B[0m\n\u001B[0;32m    298\u001B[0m                 \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    299\u001B[0m                     \u001B[1;31m# -- loop over trials and do the jobs directly\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 300\u001B[1;33m                     \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mserial_evaluate\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    301\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    302\u001B[0m                 \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtrials\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrefresh\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\hyperopt\\fmin.py\u001B[0m in \u001B[0;36mserial_evaluate\u001B[1;34m(self, N)\u001B[0m\n\u001B[0;32m    176\u001B[0m                 \u001B[0mctrl\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mbase\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mCtrl\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtrials\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcurrent_trial\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mtrial\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    177\u001B[0m                 \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 178\u001B[1;33m                     \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdomain\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mevaluate\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mspec\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mctrl\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    179\u001B[0m                 \u001B[1;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    180\u001B[0m                     \u001B[0mlogger\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0merror\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"job exception: %s\"\u001B[0m \u001B[1;33m%\u001B[0m \u001B[0mstr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0me\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\hyperopt\\base.py\u001B[0m in \u001B[0;36mevaluate\u001B[1;34m(self, config, ctrl, attach_attachments)\u001B[0m\n\u001B[0;32m    890\u001B[0m                 \u001B[0mprint_node_on_error\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrec_eval_print_node_on_error\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    891\u001B[0m             )\n\u001B[1;32m--> 892\u001B[1;33m             \u001B[0mrval\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfn\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mpyll_rval\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    893\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    894\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mrval\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0mfloat\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mint\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnumber\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_22720\\2588841040.py\u001B[0m in \u001B[0;36mobjective\u001B[1;34m(sample, dataset_df, features, target)\u001B[0m\n\u001B[0;32m     21\u001B[0m     \u001B[0mrng\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcheck_random_state\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     22\u001B[0m     \u001B[0mcv\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mKFold\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mn_splits\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m10\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mrandom_state\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mrng\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mshuffle\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mTrue\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 23\u001B[1;33m     mse = cross_val_score(\n\u001B[0m\u001B[0;32m     24\u001B[0m         \u001B[0mmodel\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     25\u001B[0m         \u001B[0mpreprocessor\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfit_transform\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdataset_df\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mloc\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfeatures\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001B[0m in \u001B[0;36mcross_val_score\u001B[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001B[0m\n\u001B[0;32m    507\u001B[0m     \u001B[0mscorer\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcheck_scoring\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mestimator\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mscoring\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mscoring\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    508\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 509\u001B[1;33m     cv_results = cross_validate(\n\u001B[0m\u001B[0;32m    510\u001B[0m         \u001B[0mestimator\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mestimator\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    511\u001B[0m         \u001B[0mX\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mX\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001B[0m in \u001B[0;36mcross_validate\u001B[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001B[0m\n\u001B[0;32m    265\u001B[0m     \u001B[1;31m# independent, and that it is pickle-able.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    266\u001B[0m     \u001B[0mparallel\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mParallel\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mn_jobs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mn_jobs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mverbose\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mverbose\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mpre_dispatch\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mpre_dispatch\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 267\u001B[1;33m     results = parallel(\n\u001B[0m\u001B[0;32m    268\u001B[0m         delayed(_fit_and_score)(\n\u001B[0;32m    269\u001B[0m             \u001B[0mclone\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mestimator\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, iterable)\u001B[0m\n\u001B[0;32m   1054\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1055\u001B[0m             \u001B[1;32mwith\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_backend\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mretrieval_context\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1056\u001B[1;33m                 \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mretrieve\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1057\u001B[0m             \u001B[1;31m# Make sure that we get a last message telling us we are done\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1058\u001B[0m             \u001B[0melapsed_time\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtime\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtime\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m-\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_start_time\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001B[0m in \u001B[0;36mretrieve\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    933\u001B[0m             \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    934\u001B[0m                 \u001B[1;32mif\u001B[0m \u001B[0mgetattr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_backend\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m'supports_timeout'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;32mFalse\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 935\u001B[1;33m                     \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_output\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mextend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mjob\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtimeout\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtimeout\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    936\u001B[0m                 \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    937\u001B[0m                     \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_output\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mextend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mjob\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001B[0m in \u001B[0;36mwrap_future_result\u001B[1;34m(future, timeout)\u001B[0m\n\u001B[0;32m    540\u001B[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001B[0;32m    541\u001B[0m         \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 542\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mfuture\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mresult\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtimeout\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mtimeout\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    543\u001B[0m         \u001B[1;32mexcept\u001B[0m \u001B[0mCfTimeoutError\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    544\u001B[0m             \u001B[1;32mraise\u001B[0m \u001B[0mTimeoutError\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\concurrent\\futures\\_base.py\u001B[0m in \u001B[0;36mresult\u001B[1;34m(self, timeout)\u001B[0m\n\u001B[0;32m    439\u001B[0m                     \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__get_result\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    440\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 441\u001B[1;33m                 \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_condition\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mwait\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtimeout\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    442\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    443\u001B[0m                 \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_state\u001B[0m \u001B[1;32min\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0mCANCELLED\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mCANCELLED_AND_NOTIFIED\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\threading.py\u001B[0m in \u001B[0;36mwait\u001B[1;34m(self, timeout)\u001B[0m\n\u001B[0;32m    310\u001B[0m         \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m    \u001B[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    311\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mtimeout\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 312\u001B[1;33m                 \u001B[0mwaiter\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0macquire\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    313\u001B[0m                 \u001B[0mgotit\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mTrue\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    314\u001B[0m             \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "\n",
    "best = fmin(SPI_objective, space, tpe.suggest, 1000, trials=trials, rstate=np.random.default_rng(SEED))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "best_params = space_eval(space, best)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "best"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "best = {k.replace('gradient_boosting_regressor__',''): v for k, v in best.items()}\n",
    "best['max_depth'] = int(best['max_depth'])\n",
    "best['n_estimators'] = int(best['n_estimators'])\n",
    "best"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_train = train[FEATURES]\n",
    "y_train = train[TARGET]\n",
    "X_test = test[FEATURES]\n",
    "y_test = test[TARGET]\n",
    "\n",
    "####################################\n",
    "GBR_pipe = Pipeline(steps=[('preprocessing', preprocessor), ('reg', GradientBoostingRegressor(**best))])\n",
    "GBR_pipe"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import joblib\n",
    "joblib.dump(GBR_pipe, 'HyperParamTuned_GRB_Pipeline_Model.pkl')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "################################\n",
    "GBR_pipe.fit(X_train, y_train)\n",
    "y_pred = GBR_pipe.predict(X_test)\n",
    "test['SPI_PRED'] = y_pred\n",
    "#####################################\n",
    "RMSE, MAE, MAPE = collect_error_metrics(test, 'SPI', 'SPI_PRED')\n",
    "score = r2_score(y_test, y_pred)\n",
    "print(RMSE,MAE,MAPE)\n",
    "print(\"The accuracy of our model is {}%\".format(round(score, 2) *100))\n",
    "\n",
    "\n",
    "# model_stats.loc[len(model_stats.index)] = [model_names_list[est], RMSE, MAE, MAPE, score]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "spi_all = pd.concat([train,test], sort = False)\n",
    "_ = spi_all[['SPI','SPI_PRED']].plot(figsize=(15, 5))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1)\n",
    "f.set_figheight(5)\n",
    "f.set_figwidth(15)\n",
    "_ = spi_all[['SPI_PRED','SPI']].plot(ax=ax,\n",
    "                                              style=['-','.'])\n",
    "ax.set_ylim(-3, 3)\n",
    "ax.set_xbound(lower='01-01-2016', upper='02-01-2016')\n",
    "plot = plt.suptitle('Month of predictions, Jan, 2016')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def unpack(x):\n",
    "    if x:\n",
    "        return x[0]\n",
    "    return np.nan\n",
    "\n",
    "\n",
    "def handleNaming(x):\n",
    "    if x == 0:\n",
    "        return RANDOM_FOREST_REGRESSOR\n",
    "    elif x == 1:\n",
    "        return GRADIENT_BOOSTING_REGRESSOR\n",
    "    elif x == 2:\n",
    "        return SGD_REGRESSOR\n",
    "    else:\n",
    "        return XGB_REGRESSOR"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# def extract_top_n_models(trials, n):\n",
    "#     \"\"\"\n",
    "#     Extract top n^th models and their parameters from a HyperOpt Trials object\n",
    "#\n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     trials : HyperOpt Trials object\n",
    "#         HyperOpt Trials object\n",
    "#     n : int\n",
    "#         Number of top models to extract\n",
    "#\n",
    "#     Returns\n",
    "#     -------\n",
    "#     top_n_models : list\n",
    "#         List of top n^th models\n",
    "#     top_n_params : list\n",
    "#         List of top n^th models' parameters\n",
    "#     \"\"\"\n",
    "#     top_n_models = []\n",
    "#     top_n_params = []\n",
    "#     for i in range(n):\n",
    "#         top_n_models.append(trials.best_trial['result']['model'])\n",
    "#         top_n_params.append(trials.best_trial['misc']['vals'])\n",
    "#     return top_n_models, top_n_params\n",
    "#\n",
    "# top_n_models, top_n_params = extract_top_n_models(trials, 10)\n",
    "#\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# We'll first turn each trial into a series and then stack those series together as a dataframe.\n",
    "trials_df = pd.DataFrame([pd.Series(t[\"misc\"][\"vals\"]).apply(unpack) for t in trials])\n",
    "# Then we'll add other relevant bits of information to the correct rows and perform a couple of\n",
    "# mappings for convenience\n",
    "trials_df[\"loss\"] = [t[\"result\"][\"loss\"] for t in trials]\n",
    "trials_df[\"trial_number\"] = trials_df.index\n",
    "trials_df[MODEL_CHOICE] = trials_df[MODEL_CHOICE].apply(\n",
    "    lambda x: RANDOM_FOREST_REGRESSOR if x == 0 else GRADIENT_BOOSTING_REGRESSOR\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# We'll first turn each trial into a series and then stack those series together as a dataframe.\n",
    "trials_df = pd.DataFrame([pd.Series(t[\"misc\"][\"vals\"]).apply(unpack) for t in trials])\n",
    "# Then we'll add other relevant bits of information to the correct rows and perform a couple of\n",
    "# mappings for convenience\n",
    "trials_df[\"loss\"] = [t[\"result\"][\"loss\"] for t in trials]\n",
    "trials_df[\"trial_number\"] = trials_df.index\n",
    "trials_df[MODEL_CHOICE] = trials_df[MODEL_CHOICE].apply(\n",
    "    lambda x: handleNaming(x)\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from plotly import express as px\n",
    "from plotly import graph_objects as go\n",
    "from plotly import offline as pyo\n",
    "\n",
    "pyo.init_notebook_mode()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def extract_top_models_from_hyperopt(trials_df):\n",
    "    best_params_per_model = trials_df.groupby(['model_choice']).min().sort_values(by='loss', ascending=True)\n",
    "    MultiModelParams = []\n",
    "    for i in range(len(list(best_params_per_model.index))):\n",
    "        n_params_series = best_params_per_model.iloc[i].dropna().drop(['loss', 'trial_number'])\n",
    "        n_model_name = n_params_series.name\n",
    "        temp = {i: {'model_name': n_model_name}}\n",
    "        repl = f\"{n_model_name}__\"\n",
    "        param_dict = {}\n",
    "        for j in n_params_series.index:\n",
    "            param_dict[j.replace(repl, \"\")] = n_params_series[j]\n",
    "            try:\n",
    "                if param_dict['max_depth'] is not None:\n",
    "                    param_dict['max_depth'] = int(param_dict['max_depth'])\n",
    "                if param_dict['n_estimators'] is not None:\n",
    "                    param_dict['n_estimators'] = int(param_dict['n_estimators'])\n",
    "\n",
    "            except KeyError:\n",
    "                continue\n",
    "        if  temp[i]['model_name'] == 'stochastic_gradient_descent_regressor':\n",
    "                param_dict['n_iter_no_change'] = 15\n",
    "                param_dict['max_iter'] = 200\n",
    "                param_dict['penalty'] = 'l2'\n",
    "        temp[i]['params'] = param_dict\n",
    "        MultiModelParams.append(temp)\n",
    "    return MultiModelParams\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "top_models_params = extract_top_models_from_hyperopt(trials_df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "top_models_params"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "model_names_to_class = {\n",
    "    'gradient_boosting_regressor': GradientBoostingRegressor,\n",
    "    'random_forest_regressor': RandomForestRegressor,\n",
    "    'xgboost_regressor': xgboost.XGBRegressor,\n",
    "    'stochastic_gradient_descent_regressor': SGDRegressor\n",
    "}\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "from utils import collect_error_metrics\n",
    "\n",
    "def generate_multi_model_lists(model_params, model_names_to_class):\n",
    "    my_model_params = model_params\n",
    "    estimator_list = []\n",
    "    model_names_list = []\n",
    "    for i in range(len(my_model_params)):\n",
    "        model_name = my_model_params[i][i]['model_name']\n",
    "        model = model_names_to_class[model_name]\n",
    "        untuned_n_pipe = model()\n",
    "        params = my_model_params[i][i]['params']\n",
    "        tuned_n_pipe = model(**params)\n",
    "        ###############################\n",
    "        estimator_list.append(untuned_n_pipe)\n",
    "        model_names_list.append(f\"untuned_{model_name}\")\n",
    "        ################################\n",
    "        estimator_list.append(tuned_n_pipe)\n",
    "        model_names_list.append(model_name)\n",
    "    return estimator_list, model_names_list\n",
    "\n",
    "\n",
    "estimator_list, model_names_list = generate_multi_model_lists(model_params=top_models_params,\n",
    "                                                              model_names_to_class=model_names_to_class)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "estimator_list"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "def run_multi_model(train, test, FEATURES, TARGET, estimator_list, model_names_list):\n",
    "    pred_data = {}\n",
    "    model_stats = pd.DataFrame({'model_name': [], 'real_mean_squared_error': [], 'mean_absolute_error': [],\n",
    "                                'mean_absolute_percentage_error': [], 'accuracy_score': []})\n",
    "    n_classes = 3\n",
    "    CLFS = []\n",
    "    y_scores = []\n",
    "    for est in range(len(estimator_list)):\n",
    "        n_test = test.copy()\n",
    "        X_train = train[FEATURES]\n",
    "        y_train = train[TARGET]\n",
    "        X_test = n_test[FEATURES]\n",
    "        y_test = n_test[TARGET]\n",
    "        X = preprocessor.fit_transform(X_train.loc[:, FEATURES])\n",
    "        ################################\n",
    "        clf = estimator_list[est]\n",
    "        clf.fit(X=X, y=y_train)\n",
    "        CLFS.append(clf)\n",
    "        y_pred = clf.predict(X_test)\n",
    "        n_test['SPI_PRED'] = y_pred\n",
    "        pred_data[model_names_list[est]] = y_pred\n",
    "        #####################################\n",
    "        RMSE, MAE, MAPE = collect_error_metrics(n_test, 'SPI', 'SPI_PRED')\n",
    "        score = r2_score(y_test, y_pred)\n",
    "        model_stats.loc[len(model_stats.index)] = [model_names_list[est], RMSE, MAE, MAPE, score]\n",
    "\n",
    "    return pred_data, CLFS, model_stats\n",
    "\n",
    "\n",
    "pred_data, CLFS, model_stats = run_multi_model(train=train, test=test, FEATURES=FEATURES, TARGET=TARGET, estimator_list=estimator_list, model_names_list=model_names_list)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "[i.replace(list(best_params_per_model.iloc[0].dropna().drop(['loss', 'trial_number']).index)\n",
    "\n",
    " n_model_params = []\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.scatterplot(data=trials_df, x='trial_number', y='loss', hue=MODEL_CHOICE)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}